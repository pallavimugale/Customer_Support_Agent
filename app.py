import streamlit as st
import faiss
import pandas as pd

from src.helper import semantic_similarity, call_llm

#fun for display responce and handle feedback
def display_response(query,df,index):

    #call the semantic_similaruty for getting most relevent instruction form the query
    distances , indices =semantic_similarity(query,index,'all-MiniLM-L6-v2')

    #search the original datafream for similar intruction and pass to it new data frame
    top_similar_instructions= df.iloc[indices[0]].reset_index(drop=True)
    top_similar_instructions['distance']=distances[0]

    #display the similar res from internal dataset
   # st.write("Res from Internal Dataset")
   # st.write(top_similar_intructions[['instruction','intent','response']])


     #display the response generated by LLM according to prompt in helper.py
    st.write(f"Following responses will be generated:\n"
            "1. Urgency of the query based on the input query on a scale of 1-5 where 1 is least urgent and 5 is most urgent.\n"
            "2. Categorize the input query into sales, product, operations etc.\n"
            "3. Generated Response from LLM.")
    st.write("## Response from LLM below (wait a few seconds)")
    llm_response = call_llm(query, top_similar_instructions['response'].tolist())
    st.write(llm_response)

    return llm_response, top_similar_instructions

st.title("IntelliServe â€“ AI-Driven Customer Helpdesk")


#taking input query from customer
query=st.text_input("User Query:",key='query')

#load the created vector DB and the dataset for the RAG
index = faiss.read_index('vector_store/faiss_index.index')
df = pd.read_csv('Customer_Support_Training_Dataset/Customer_Support_Training_Dataset.csv')

if st.button("Get response from internal dataset and Run LLM"):
    if not query:
        st.error("Please enter a query.")
    else:
        #call the display_response function to get the LLM response and similar instructions
        llm_response, top_similar_instructions = display_response(query, df, index)
        
        #store the LLM response and similar instructions in session state
        st.session_state['llm_response'] = llm_response
        st.session_state['top_similar_instructions'] = top_similar_instructions

#check if LLM response is stored in session state
if 'llm_response' in st.session_state:
    llm_response = st.session_state['llm_response']
    top_similar_instructions = st.session_state['top_similar_instructions']

    #add feedback section
    st.write("## Feedback")
    feedback = st.text_area("Provide feedback or additional instructions for the response:", key="feedback")
    
    if st.button("Accept Response"):
        st.success("Response has been submitted.")
    
    if st.button("Regenerate Response"):
        if feedback:
            #generate a new query for LLM based on the feedback
            new_query = f'''Regenerate third point of this response: {llm_response}.\n 
                    You must only regenerate third point according to the feedback later. Do not change 1st and 2nd point at any cost but always have them in the final output.\n Feedback: {feedback}'''
            print(new_query)
            
            #call LLM with the new query and get the regenerated response
            new_llm_response = call_llm(new_query, top_similar_instructions['response'].tolist())
            
            #display the new LLM response
            st.write("## New Response from LLM (wait a few seconds)")
            st.write(new_llm_response)
            
            #update the LLM response in session state
            st.session_state['llm_response'] = new_llm_response
        else:
            st.error("Please provide feedback to regenerate the response.")
   
